# %% [markdown]
# # Downloading and preparing stock data

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import statsmodels.api as sm
import tensorflow as tf
import yfinance as yf
from keras.layers import Dense
from keras.models import Sequential
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score
from sklearn.model_selection import ParameterGrid
from sklearn.preprocessing import MinMaxScaler, scale
from ta.momentum import rsi
from ta.trend import sma_indicator

start_date = '2010-01-01'
end_date = '2020-01-01'
ticker = 'INVE-B.ST'
df = yf.download(ticker, start_date, end_date)
df.index = df.index.date
df.index.name = "Date"

df.head()

# %%
# check for missing values

df.isna().any()

# %%
# Stock price plot

df['Adj Close'].plot(figsize=(8, 5))
plt.title("INVE-B Stock Price", fontsize=17)
plt.xlabel("Time", fontsize=14)
plt.ylabel("Price", fontsize=14)
plt.grid(which="major", color='k', linestyle='-.', linewidth=0.5)

# %%

plt.figure(figsize=(8, 5))
df['Adj Close'].pct_change().plot.hist(bins=50)

# %%
# Correlation coefficient

df['5d_future_close'] = df['Adj Close'].shift(-5)
df['5d_close_future_pct'] = df['5d_future_close'].pct_change(5)
df['5d_close_pct'] = df['Adj Close'].pct_change(5)

corr = df[['5d_close_pct', '5d_close_future_pct']].corr()
corr

# %%
# Scatterplot adj close vs future close

plt.figure(figsize=(8, 5))
plt.scatter(df['Adj Close'], df['5d_future_close'], s=3)
plt.xlabel("Adj Close")
plt.ylabel("5d_future_close")

# %% [markdown]
# scatterplot, 5d close future pct vs 5d close pct
# %%
plt.figure(figsize=(8, 5))
plt.scatter(df['5d_close_future_pct'], df['5d_close_pct'], s=3)
plt.xlabel("5d_close_future_pct")
plt.ylabel("5d_close_pct")

# %% [markdown]
# # Targets and features

# $$ RSI = 100 - \frac{100}{1+\frac{\text{average of upward price change}}{\text{average of downward price change}}}

# %%

feature_names = ['5d_close_pct']

for n in [14, 30, 50, 200]:  # Create the moving average indicator and divide by Adj_Close

    df['ma'+str(n)] = sma_indicator(df['Adj Close'],
                                    window=n, fillna=False) / df['Adj Close']
    df['rsi'+str(n)] = rsi(df['Adj Close'],
                           window=n, fillna=False)
    feature_names = feature_names + ['ma' + str(n), 'rsi' + str(n)]

# %%
# New features based on volume
new_features = ['Volume_1d_change', 'Volume_1d_change_SMA']
feature_names.extend(new_features)
df['Volume_1d_change'] = df['Volume'].pct_change()
df['Volume_1d_change_SMA'] = sma_indicator(
    df['Volume_1d_change'], window=5, fillna=False)

df = df.dropna()

# %%
# Create features and targets
# use feature_names for features; '5d_close_future_pct' for targets

features = df[feature_names]
targets = df['5d_close_future_pct']

# Create DataFrame from target column and feature columns
feature_and_target_cols = ['5d_close_future_pct']+feature_names
feat_targ_df = df[feature_and_target_cols]

# Calculate correlation matrix
corr = feat_targ_df.corr()
print(corr)


# %%
# plot SMAs together

df[['ma14', 'ma30', 'ma50', 'ma200']].plot(figsize=(8, 5))
plt.title("INVE-B Stock Price Normalized", fontsize=17)
plt.xlabel("Time", fontsize=14)
plt.ylabel("Price", fontsize=14)
plt.grid(which="major", color='k', linestyle='-.', linewidth=0.5)

# %%

plt.figure(figsize=(8, 8), dpi=80)
sns.heatmap(corr, annot=True, annot_kws={"size": 10})
plt.yticks(rotation=0, size=12)
plt.xticks(rotation=90, size=12)  # fix ticklab
plt.tight_layout()  # fits plot area to the plot, "tightly"
plt.show()  # show the plot

plt.figure(figsize=(8, 8), dpi=80)
plt.scatter(df['5d_close_future_pct'], df['ma200'], s=3)
plt.xlabel("5d_close_future_pct")
plt.ylabel("Volume_1d_change_SMA")
plt.show()

# %% [markdown]
# # Linear Regression Model

# %% [markdown]
# $$ \Large y=\beta_0 + \beta_1x

# %%

linear_features = sm.add_constant(features)

train_size = int(0.85*targets.shape[0])
train_features = linear_features[:train_size]
train_targets = targets[:train_size]
test_features = linear_features[train_size:]
test_targets = targets[train_size:]
print(linear_features.shape, train_features.shape, test_features.shape)

# %%

model = sm.OLS(train_targets, train_features)
results = model.fit()
print(results.summary())
print(results.pvalues)

train_predictions = results.predict(train_features)
test_predictions = results.predict(test_features)

# %%

plt.figure(figsize=(8, 8))
plt.scatter(train_predictions, train_targets,
            alpha=0.2, color='b', label='train', s=6)
plt.scatter(test_predictions, test_targets,
            alpha=0.2, color='r', label='test', s=6)

xmin, xmax = plt.xlim()
plt.plot(np.arange(xmin, xmax, 0.01), np.arange(xmin, xmax, 0.01), c='k')
plt.xlabel('Predictions')
plt.ylabel('Actual')
plt.legend()
# plt.xlim([-0.02,0.02])
# plt.ylim([-0.15,0.15])

# %%[markdown]
# ## Random Forest

# %%

rfr = RandomForestRegressor(n_estimators=200)
rfr.fit(train_features, train_targets)

print(rfr.score(train_features, train_targets))
print(rfr.score(test_features, test_targets))

grid = {'n_estimators': [200], 'max_depth': [3],
        'max_features': [4, 8], 'random_state': [42]}
test_scores = []

for g in ParameterGrid(grid):
    rfr.set_params(**g)  # ** is "unpacking" the dictionary
    rfr.fit(train_features, train_targets)
    test_scores.append(rfr.score(test_features, test_targets))


best_idx = np.argmax(test_scores)
print(test_scores[best_idx], ParameterGrid(grid)[best_idx])
# %%

rfr = RandomForestRegressor(
    n_estimators=200, max_depth=3, max_features=8, random_state=42)
rfr.fit(train_features, train_targets)

train_predictions = rfr.predict(train_features)
test_predictions = rfr.predict(test_features)

plt.figure(figsize=(8, 8), dpi=80)
plt.scatter(train_targets, train_predictions, label='train', s=5)
plt.scatter(test_targets, test_predictions, label='test', s=5)
plt.legend()
plt.show()


# %%

importances = rfr.feature_importances_

# Get the index of importances from greatest importance to least

sorted_index = np.argsort(importances)[::-1]
x = range(len(importances))

# Create tick labels


plt.figure(figsize=(8, 8), dpi=80)
plt.bar(x, importances[sorted_index])

# %% [markdown]
# ## Standardizing the data

# %%

scaled_train_features = scale(train_features)
scaled_test_features = scale(test_features)

f, ax = plt.subplots(nrows=2, ncols=1)
train_features.iloc[:, 2].hist(ax=ax[0])
ax[1].hist(scaled_train_features[:, 2])
plt.show()

#%%[markdown]
# ## K-NN

from sklearn.neighbors import KNeighborsRegressor

for n in range(2,13,1):
    # Create and fit the KNN model
    knn = KNeighborsRegressor(n_neighbors=n)
    
    # Fit the model to the training data
    knn.fit(scaled_train_features, train_targets)
    
    # Print number of neighbors and the score to find the best value of n
    print("n_neighbors =", n)
    print('train, test scores')
    print(knn.score(scaled_train_features, train_targets))
    print(knn.score(scaled_test_features, test_targets))
    print()  # prints a blank line

#%% [markdown]
# Evaluate model performance

# Create the model with the best-performing n_neighbors of 12

knn = KNeighborsRegressor(12)


# Fit the model

knn.fit(scaled_train_features, train_targets)


# Get predictions for train and test sets

train_predictions = knn.predict(scaled_train_features)
test_predictions = knn.predict(scaled_test_features)


# Plot the actual vs predicted values

plt.figure(figsize=(8, 8), dpi=80)
plt.scatter(train_predictions, train_targets, label='train', s = 5)
plt.scatter(test_predictions, test_targets, label='test', s = 5)
plt.legend()
plt.show()
# %% [markdown]
# ## Neural Network Model

model_1 = Sequential()

model_1.add(
    Dense(100, input_dim=scaled_train_features.shape[1], activation='relu'))
model_1.add(Dense(20, activation='relu'))
model_1.add(Dense(1, activation='linear'))
model_1.compile(optimizer='adam', loss='mse')
history = model_1.fit(scaled_train_features, train_targets, epochs=100)
# %%

plt.figure(figsize=(8, 8), dpi=80)
plt.plot(history.history['loss'])
plt.title('loss:'+str(round(history.history['loss'][-1], 6)))
plt.show()

# %%

train_preds = model_1.predict(scaled_train_features)
test_preds = model_1.predict(scaled_test_features)
print(r2_score(train_targets, train_predictions))
print(r2_score(test_targets, test_preds))
# %%

plt.figure(figsize=(8, 8), dpi=80)
plt.scatter(train_preds, train_targets, label='train', s=5)
plt.scatter(test_preds, test_targets, label='test', s=5)
plt.legend()
plt.show()
# %%
